name: ollama-webui

services:
  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    environment:
      - 'OLLAMA_BASE_URL=http://host.docker.internal:11434'
      - 'PORT=3000'
    volumes:
      - open-webui:/app/backend/data
  
  npm:
    image: 'jc21/nginx-proxy-manager:latest'
    ports:
      - '80:80'
      - '81:81'
      - '443:443'
    restart: unless-stopped
    volumes:
      - ./npm/data:/data
      - ./npm/letsencrypt:/etc/letsencrypt

volumes:
  open-webui: {}
